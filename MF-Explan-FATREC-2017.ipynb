{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<BR>\n",
    "<BR>\n",
    "<center>\n",
    "<font style=\"font-size:34px\">Exploring Explanations for <BR><BR>Matrix Factorization Recommender Systems<BR><BR><BR>\n",
    "</font>\n",
    "<BR><BR>\n",
    "<font style=\"font-size:20px\">\n",
    "FATREC 2017\n",
    "<BR><BR>\n",
    "August 31, 2017\n",
    "<BR><BR><BR><BR><BR>\n",
    "Bashir Rastegarpanah, Mark Crovella, and Krishna P. Gummadi\n",
    "<BR><BR><BR>\n",
    "This talk is available at <span style=\"font-family: monospace;\">https://github.com/mcrovella/FATREC-2017-Talk</span>\n",
    "<table style=\"border-style: hidden\">\n",
    "<tr>\n",
    "<td style=\"border-style: hidden; padding: 30px\"><IMG src='images/BUlogo.png' width=150/></td>\n",
    "<td style=\"border-style: hidden; padding: 30px\"><IMG src='images/mpi-sws-logo.svg' width=225/></td>\n",
    "<td style=\"border-style: hidden; padding: 30px\"><IMG src='images/nsf-logo.jpg' width=150/></td>\n",
    "</tr>\n",
    "</table>\n",
    "<BR>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import slideUtilities as sl\n",
    "from importlib import reload\n",
    "from datetime import datetime\n",
    "from IPython.display import Image\n",
    "from IPython.display import display_html\n",
    "from IPython.display import display\n",
    "from IPython.display import Math\n",
    "from IPython.display import Latex\n",
    "from IPython.display import HTML\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
       "    display: None ! important;\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    " .container.slides .celltoolbar, .container.slides .hide-in-slideshow {\n",
    "    display: None ! important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "%Set up useful MathJax (Latex) macros.\n",
    "%See http://docs.mathjax.org/en/latest/tex.html#defining-tex-macros\n",
    "%These are for use in the slideshow\n",
    "$\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}$\n",
    "$\\newcommand{\\vx}{{\\mathbf x}}$\n",
    "$\\newcommand{\\hx}{\\hat{\\mathbf x}}$\n",
    "$\\newcommand{\\vbt}{{\\mathbf\\beta}}$\n",
    "$\\newcommand{\\vy}{{\\mathbf y}}$\n",
    "$\\newcommand{\\vz}{{\\mathbf z}}$\n",
    "$\\newcommand{\\R}{{\\mathbb{R}}}$\n",
    "$\\newcommand{\\vu}{{\\mathbf u}}$\n",
    "$\\newcommand{\\vv}{{\\mathbf v}}$\n",
    "$\\newcommand{\\vw}{{\\mathbf w}}$\n",
    "$\\newcommand{\\col}{{\\operatorname{Col}}}$\n",
    "$\\newcommand{\\nul}{{\\operatorname{Nul}}}$\n",
    "$\\newcommand{\\vb}{{\\mathbf b}}$\n",
    "$\\newcommand{\\va}{{\\mathbf a}}$\n",
    "$\\newcommand{\\ve}{{\\mathbf e}}$\n",
    "$\\newcommand{\\setb}{{\\mathcal{B}}}$\n",
    "$\\newcommand{\\rank}{{\\operatorname{rank}}}$\n",
    "$\\newcommand{\\vp}{{\\mathbf p}}$"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "\\newcommand{\\mat}[1]{\\left[\\begin{array}#1\\end{array}\\right]}\n",
    "\\newcommand{\\vx}{{\\mathbf x}}\n",
    "\\newcommand{\\hx}{\\hat{\\mathbf x}}\n",
    "\\newcommand{\\vbt}{{\\mathbf\\beta}}\n",
    "\\newcommand{\\vy}{{\\mathbf y}}\n",
    "\\newcommand{\\vz}{{\\mathbf z}}\n",
    "\\newcommand{\\vb}{{\\mathbf b}}\n",
    "\\newcommand{\\vu}{{\\mathbf u}}\n",
    "\\newcommand{\\vv}{{\\mathbf v}}\n",
    "\\newcommand{\\vw}{{\\mathbf w}}\n",
    "\\newcommand{\\va}{{\\mathbf a}}\n",
    "\\newcommand{\\ve}{{\\mathbf e}}\n",
    "\\newcommand{\\vp}{{\\mathbf p}}\n",
    "\\newcommand{\\R}{{\\mathbb{R}}}\n",
    "\\newcommand{\\col}{{\\operatorname{Col}}}\n",
    "\\newcommand{\\nul}{{\\operatorname{Nul}}}\n",
    "\\newcommand{\\rank}{{\\operatorname{rank}}}\n",
    "\\newcommand{\\setb}{{\\mathcal{B}}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We're interested in explaining the recommendations that come from a recommender system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "When one uses a _neighborhood based_ recommender system, explanations are often made in terms of movies previously viewed:  \n",
    "\n",
    "> \"You have been recommended _The Matrix_ because you liked _Star Wars._\"  \n",
    "\n",
    "This explanation is easily computed and derives directly from the way that the neighborhood approach works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There a good aspects of this approach: the statement is made in familiar terms (\"_Star Wars_\") and the reasoning is simple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recommender systems based on _matrix factorization_ are a different story.  \n",
    "\n",
    "Here, users and items are placed into a _latent space_.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Item $i$ is assigned a vector $\\vu_i$ and user $j$ is assigned $\\vv_j$, and the estimated rating for an item is formed as $\\vu_i^T\\vv_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In general the dimensions of the latent space (i.e., the components of $\\vu_i$ and $\\vv_j$) don't have any simple interpretation, \n",
    "\n",
    "and so examining the computation $\\vu_i^T\\vv_j$ doesn't shed much light on the reasons behind the recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So the first question (and one of our main questions) is: what sort of explanations are useful to the user of a Recommender System?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's consider the case in which the system has given user $j$ a recommendation for item $i$ with an estimated rating of $\\hat{x}_{ij}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two questions seem reasonable:\n",
    "\n",
    "1. Which previous ratings have __contributed__ the most to the predicted rating $\\hat{x}_{ij}$ ?\n",
    "2. Which previous ratings have the most __influence__ over the predicted rating $\\hat{x}_{ij}$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Note that the first question is getting at: \"how did the system get this rating?\", \n",
    "\n",
    "while the second question is getting at \"how would the rating change if things had been different?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Potential Answers to Questions 1 and 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The most useful answers to these questions would seem to be in terms of previously rated items by the same user.\n",
    "\n",
    "So let's consider some user $j$, who has a known rating $x_{kj}$,\n",
    "and let's consider one of that user's predicted ratings $\\hat{x}_{ij}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To answer question 1, the simplest approach would be to define a linear (additive) model:\n",
    "\n",
    "$$\\hat{x}_{ij} \\approx \\sum_{k\\in R(j)} \\alpha_k x_{kj}.$$\n",
    "where $R(j)$ is the set of items that have been previously rated by user $j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then we can term $\\gamma_k = \\alpha_kx_{kj}$ the __impact__ of known rating $x_{kj}$ on the predicted rating $\\hat{x}_{ij}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is easily interpretable: each previous rating has some impact on the recommendation, and the recommendation is the sum of the impacts.   \n",
    "\n",
    "How to choose the $\\alpha$s is an open question that we'll return to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "To asnswer question 2 (\"influence\"), we note that a number of previous papers on classifiers have proposed using the __gradient__ of the classification function.\n",
    "\n",
    "[Baehrens et al, JMLR, 2010; Sundarajan et al, ICML 2017] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we will define\n",
    "$$ \\beta_k = \\frac{\\partial \\hat{x}_{ij}}{\\partial x_{kj}}$$\n",
    "and we will call $\\beta_k$ the __influence__ of $x_{kj}$ on $\\hat{x}_{ij}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computing the Gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's consider the challenges of using a gradient based approach with matrix factorization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Assume $X \\in \\R^{m \\times n}$ is a\n",
    "partially observed, real-valued matrix containing user ratings.\n",
    "\n",
    "An MF recommender system attempts to \n",
    "estimate unknown elements of the rating matrix.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To do so, it\n",
    "find factors $U \\in \\R^{\\ell \\times m}$ and $V \\in R^{\\ell \\times n}$ such that $U^T V$\n",
    "agrees with the known positions in $X$. \n",
    "\n",
    "The unknown\n",
    "ratings are then estimated by setting $\\hat{X} = U^T V$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's represent the predictions made by the recommender system using a function $f$.  \n",
    "\n",
    "For any user\n",
    "$j$, the function $f$ returns the prediction of __all__ item ratings for user $j$ given\n",
    "the set of __known__ item ratings for user $j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our goal is to compute the Jacobian\n",
    "of the function $f()$ evaluated at $\\vx_j$.   That is, we seek:\n",
    "$$\n",
    "J^{(j)} =  \\frac{\\partial f(\\vx_j)}{\\partial \\vx_j}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is a hard function to analyze in general: a change to any known rating $\\vx_{ij}$, after re-running model fitting and predicting (via the matrix factorization algorithm) can result in nonlinear changes to the predicted entries in $\\vx_j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Common Case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "To address this, we make the following observation.  \n",
    "\n",
    "In many cases, there will be many more users of the system than items.   \n",
    "\n",
    "For example, a movie recommendation system may have\n",
    "millions of users but only thousands of movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So the rating matrix $X$ is short and wide, meaning that $U^T$ is short and $V$ is wide.\n",
    "\n",
    "$$ m\\left\\{\\begin{array}{c}\\;\\\\\\;\\\\\\;\\end{array}\\right.\\;\\;\\overbrace{\\left[\\begin{array}{ccccc}\\begin{array}{c}\\vdots\\\\{\\bf x_1}\\\\\\vdots\\end{array}&\\begin{array}{c}\\vdots\\\\{\\bf x_2}\\\\\\vdots\\end{array}\n",
    "&\\begin{array}{c}\\vdots\\\\{\\bf x_3}\\\\\\vdots\\end{array}&\\dots&\\begin{array}{c}\\vdots\\\\{\\bf x_n}\\\\\\vdots\\end{array}\\\\\\end{array}\\right]}^{\\large n} =\n",
    "\\overbrace{\\left[\\begin{array}{cc}\\vdots&\\vdots\\\\\\vu_1&\\vu_\\ell\\\\\\vdots&\\vdots\\end{array}\\right]}^{\\large \\ell}\n",
    "\\times\n",
    "\\left[\\begin{array}{ccccc}\\dots&\\dots&\\vv_1&\\dots&\\dots\\\\\\dots&\\dots&\\vv_\\ell&\\dots&\\dots\\end{array}\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We observe that in that case, a small change to $\\vx_{ij}$ will result mainly in changes to $V$, while $U$ will be relatively fixed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Intuitively this is because each row of $U^T$ is required to fit many more entries in $X$ than is each column of $V$.  \n",
    "\n",
    "So a change to $V$ introduces less overall error in the fit.  \n",
    "\n",
    "See the paper for more expanation and a proof."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In that case, we can show that $$\n",
    "J^{(j)} =  \\frac{\\partial f(\\vx_j)}{\\partial \\vx_j} = U^T (U W_j U^T)^{-1} U W_j\n",
    "$$\n",
    "\n",
    "where $W_j$ is a binary matrix with 1s on the diagonal in positions\n",
    "corresponding the known entries of $x_j$ (i.e., the rated items.)\n",
    "\n",
    "See paper for details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In this case then influence is simply:\n",
    "\n",
    "$$ \\beta_k = J^{(j)}_{ik}. $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Furthermore, we can show that \n",
    "$$\\hat{x}_{ij} = \\sum_{k\\in R(j)} J^{(j)}_{ik} x_{kj}.$$\n",
    "\n",
    "which gives us a natural choice for impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## In Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 642)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import MF_explan\n",
    "\n",
    "# load data from MovieLens \n",
    "# use the 50 most frequently rated movies\n",
    "ML_explainer = MF_explan.MF_explan(50)\n",
    "\n",
    "ML_explainer.ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# factor the partially observed ratings matrix\n",
    "# and compute predictions\n",
    "predictions = ML_explainer.fit_model()\n",
    "\n",
    "# choose user 164, who has rated 19 movies\n",
    "user = 164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 164\n",
      "Recommended movie: Schindler's List (1993)\n",
      "Predicted rating: 4.34\n",
      "Number of rated movies: 19\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Rated Movie                         Influence    Known rating   Impact      \n",
      "----------------------------------------------------------------------------\n",
      "Braveheart (1995)                       0.176           3.0     0.528\n",
      "Good Will Hunting (1997)                0.174           4.0     0.694\n",
      "Shawshank Redemption, The (1994)        0.167           4.5     0.753\n",
      "American Beauty (1999)                  0.147           4.0     0.586\n",
      "Pulp Fiction (1994)                     0.109           4.5     0.489\n",
      "Shrek (2001)                            0.103           4.0     0.413\n",
      "Fargo (1996)                            0.085           4.5     0.383\n",
      "Lion King, The (1994)                   0.071           4.0     0.285\n",
      "Groundhog Day (1993)                    0.069           4.0     0.274\n",
      "Toy Story (1995)                        0.063           3.5     0.219\n",
      "Lord of the Rings: The Two Towers,      0.034           2.5     0.085\n",
      "Lord of the Rings: The Return of t      0.028           3.0     0.084\n",
      "Lord of the Rings: The Fellowship       0.022           3.0     0.067\n",
      "Jurassic Park (1993)                    0.018           3.0     0.054\n",
      "Men in Black (a.k.a. MIB) (1997)       -0.010           3.5    -0.035\n",
      "Terminator, The (1984)                 -0.022           2.5    -0.056\n",
      "Dumb & Dumber (Dumb and Dumber) (1     -0.050           2.0    -0.100\n",
      "Star Wars: Episode VI - Return of      -0.069           2.5    -0.172\n",
      "Star Wars: Episode IV - A New Hope     -0.072           3.0    -0.217\n",
      "----------------------------------------------------------------------------\n",
      "sum:                                                                   4.335\n"
     ]
    }
   ],
   "source": [
    "# find the item with highest predicted rating for this user\n",
    "top_recom = ML_explainer.predictions(user).index[0]\n",
    "\n",
    "# compute the Jacobian (influence matrix) for this user\n",
    "J_j = ML_explainer.jacobian(user)\n",
    "\n",
    "# report the influence and impact of each item on the recommendation\n",
    "rpt = ML_explainer.report_recommendation(J_j, user, top_recom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### What-if using Influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Our user realizes that the recommendation is strongly influenced by _Braveheart_, and that the user is not sure she likes _Braveheart_ all that much.\n",
    "\n",
    "The influence of _Braveheart_ is 0.176, so if the user downgraded her rating by 2 points, this should reduce the predicted score for _Schindler's List_ by 2 * 0.178 = 0.356.\n",
    "\n",
    "Indeed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 164\n",
      "Recommended movie: Schindler's List (1993)\n",
      "Predicted rating: 3.97\n",
      "Number of rated movies: 19\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Rated Movie                         Influence    Known rating   Impact      \n",
      "----------------------------------------------------------------------------\n",
      "Braveheart (1995)                       0.178           1.0     0.178\n",
      "Good Will Hunting (1997)                0.174           4.0     0.698\n",
      "Shawshank Redemption, The (1994)        0.167           4.5     0.752\n",
      "American Beauty (1999)                  0.147           4.0     0.587\n",
      "Pulp Fiction (1994)                     0.108           4.5     0.485\n",
      "Shrek (2001)                            0.103           4.0     0.413\n",
      "Fargo (1996)                            0.083           4.5     0.375\n",
      "Lion King, The (1994)                   0.070           4.0     0.281\n",
      "Groundhog Day (1993)                    0.067           4.0     0.270\n",
      "Toy Story (1995)                        0.062           3.5     0.218\n",
      "Lord of the Rings: The Two Towers,      0.035           2.5     0.088\n",
      "Lord of the Rings: The Return of t      0.029           3.0     0.087\n",
      "Lord of the Rings: The Fellowship       0.023           3.0     0.070\n",
      "Jurassic Park (1993)                    0.017           3.0     0.051\n",
      "Men in Black (a.k.a. MIB) (1997)       -0.012           3.5    -0.041\n",
      "Terminator, The (1984)                 -0.022           2.5    -0.054\n",
      "Dumb & Dumber (Dumb and Dumber) (1     -0.047           2.0    -0.095\n",
      "Star Wars: Episode VI - Return of      -0.069           2.5    -0.174\n",
      "Star Wars: Episode IV - A New Hope     -0.073           3.0    -0.220\n",
      "----------------------------------------------------------------------------\n",
      "sum:                                                                   3.971\n"
     ]
    }
   ],
   "source": [
    "ML_explainer.ratings.loc['Braveheart (1995)', user] -= 2.0\n",
    "predictions = ML_explainer.fit_model()\n",
    "rpt = ML_explainer.report_recommendation(ML_explainer.jacobian(user), user, top_recom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new top recommendation is 'Usual Suspects, The (1995)'\n"
     ]
    }
   ],
   "source": [
    "top_recom = ML_explainer.predictions(user).index[0]\n",
    "print(\"The new top recommendation is '{}'\".format(top_recom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User ID: 164\n",
      "Recommended movie: Usual Suspects, The (1995)\n",
      "Predicted rating: 4.10\n",
      "Number of rated movies: 19\n",
      "\n",
      "----------------------------------------------------------------------------\n",
      "Rated Movie                         Influence    Known rating   Impact      \n",
      "----------------------------------------------------------------------------\n",
      "Fargo (1996)                            0.230           4.5     1.035\n",
      "Pulp Fiction (1994)                     0.214           4.5     0.965\n",
      "American Beauty (1999)                  0.189           4.0     0.754\n",
      "Shawshank Redemption, The (1994)        0.111           4.5     0.501\n",
      "Star Wars: Episode IV - A New Hope      0.067           3.0     0.200\n",
      "Terminator, The (1984)                  0.061           2.5     0.152\n",
      "Star Wars: Episode VI - Return of       0.054           2.5     0.135\n",
      "Groundhog Day (1993)                    0.051           4.0     0.203\n",
      "Good Will Hunting (1997)                0.047           4.0     0.188\n",
      "Jurassic Park (1993)                    0.045           3.0     0.134\n",
      "Braveheart (1995)                       0.037           1.0     0.037\n",
      "Toy Story (1995)                        0.023           3.5     0.081\n",
      "Men in Black (a.k.a. MIB) (1997)        0.013           3.5     0.044\n",
      "Lion King, The (1994)                   0.003           4.0     0.012\n",
      "Dumb & Dumber (Dumb and Dumber) (1      0.002           2.0     0.005\n",
      "Lord of the Rings: The Two Towers,     -0.015           2.5    -0.038\n",
      "Lord of the Rings: The Fellowship      -0.021           3.0    -0.064\n",
      "Lord of the Rings: The Return of t     -0.030           3.0    -0.090\n",
      "Shrek (2001)                           -0.038           4.0    -0.152\n",
      "----------------------------------------------------------------------------\n",
      "sum:                                                                   4.101\n"
     ]
    }
   ],
   "source": [
    "rpt = ML_explainer.report_recommendation(ML_explainer.jacobian(user), user, top_recom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Influence vs Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# reset the model\n",
    "ML_explainer = MF_explan.MF_explan(50)\n",
    "predictions = ML_explainer.fit_model()\n",
    "user = 164\n",
    "top_recom = ML_explainer.predictions(user).index[0]\n",
    "J_j = ML_explainer.jacobian(user)\n",
    "rpt = ML_explainer.report_recommendation(J_j, user, top_recom, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schindler's List (1993)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Influence</th>\n",
       "      <th>Known Rating</th>\n",
       "      <th>Impact</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Braveheart (1995)</th>\n",
       "      <td>0.178146</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.178146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Good Will Hunting (1997)</th>\n",
       "      <td>0.174491</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.697963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Shawshank Redemption, The (1994)</th>\n",
       "      <td>0.167219</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.752485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>American Beauty (1999)</th>\n",
       "      <td>0.146830</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.587321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pulp Fiction (1994)</th>\n",
       "      <td>0.107798</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.485093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Influence  Known Rating    Impact\n",
       "movieId                                                            \n",
       "Braveheart (1995)                  0.178146           1.0  0.178146\n",
       "Good Will Hunting (1997)           0.174491           4.0  0.697963\n",
       "Shawshank Redemption, The (1994)   0.167219           4.5  0.752485\n",
       "American Beauty (1999)             0.146830           4.0  0.587321\n",
       "Pulp Fiction (1994)                0.107798           4.5  0.485093"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(top_recom)\n",
    "rpt.sort_values('Influence',ascending=False).head()\n",
    "# rpt.sort_values('Impact',ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Are these useful?   They seem to be, but hard to be sure without more investigation.\n",
    "\n",
    "It is interesting that the influence matrix only depends on __which__ movies the user has rated -- not what the ratings are.\n",
    "\n",
    "So two users who have rated the same movies, will have the same influence matrix.\n",
    "\n",
    "Next steps: what formal properties do these explanations satisfy?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
